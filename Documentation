Documentation: 

In this project, we merge several data sources together in order to create a database of movies with their general information, including title, genre, rating, release date, actors, score,       budget, country, popularity, and viewer vote average, as well as information about the movie’s renting, including average rental price and number of customers rented. 
We began by downloading a MySQL database called Sakila, a sample database which included movie rental information. We chose this dataframe so that we could have some type of customer relation (average price and number of customers) in the final dataframe. We established a MySQL connection to this database using python code, defining a SQL query to join and aggregate data from multiple tables in Sakila. We joined data from the film, rental, inventory, payment, film_actor, language, and actor tables in order to create a comprehensive database which displayed each movie’s ID number, average rental price, number of customers rented, language, genre, release year, and actors. We stored this data as a pandas dataframe called ‘movies’. We intentionally grouped this data not by movie title, but by movie ID, because the movie titles in Salika were fabricated, and we knew we were going to be merging it with a dataset of real IMDB movies.
We next read in data from a csv file named “imdb_movies.csv”, downloaded from Kaggle. This data was loaded into a dataframe called df_csv. We created a ‘row_number’ column in this dataframe so that we could move it with the movies dataframe by ID. We chose this database because it gave us real movie information to add to our final database. 
We next merged the two dataframes based on the row_number column, and assigned the dataframe to merged_df. We renamed the columns to be consistent. 
Next, we made an API call to an external API movie database, which stored information about movies, specifically their ratings. We used this API to add rating information to our final database. We handled specific error codes and converted the JSON response to a pandas dataframe called df_API. We dropped unnecessary columns and renamed some columns in order to merge df_API to the final dataframe. 
Finally, we merged merged_df and df_API based on the movie title. The final data frame contained integrated data from the MySQL database, CSV file, and the external API. Unfortunately, the external API was much smaller than anticipated, and when merged with the previous dataframe, caused the final dataframe to only contain a few rows. However, we are really satisfied with our data integration and still feel that we were able to gather the information we were looking for about the listed movies through our code.
